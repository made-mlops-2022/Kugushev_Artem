apiVersion: v1
kind: Pod
metadata:
   name: online-inference-resources
spec:
   containers:
     - image: artemkgushev/homework2
       name: online-inference-resources
       ports:
         - containerPort: 8000
       resources:
         requests:
             memory: "50Mi"
             cpu: 1
         limits:
             memory: "500Mi"